{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vote_prediction.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "IuViXILkHfV5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Vote prediction\n",
        "\n",
        "Your friend runs an evil government and he wants to influence elections in a foreign country. His evil spy network collected data about voters in a foreign country:\n",
        "\n",
        "- 1 if a voter older then 35 years, 0 otherwise\n",
        "- 1 if a voter male, 0 otherwise\n",
        "- 1 if a voter watched PythonNN in last month, 0 otherwise\n",
        "- 1 if a voter watched Rabbit News in last month, 0 otherwise\n",
        "- 1 if a voter lives in a big city, 0 otherwise\n",
        "- 1 if a voter voted last time, 0 otherwise\n",
        "- 1 if a voter likes ice cream, 0 otherwise\n",
        "- 1 if a voter has hair, 0 otherwise\n",
        "\n",
        "An evil plan of your friend is following:\n",
        "\n",
        "- Based on 8 features predict how a person will vote\n",
        "- Model if watching Rabbit News influences voters to vote for needed option\n",
        "- Go to national parks and feed the rabbits\n",
        "- A population of rabbits will grow, more people will see them in park\n",
        "- People who will see rabbits in a park will decide to watch Rabbit News\n",
        "\n",
        "Your friend just notified you that they were able to collect information about voters, but they were not able to get information on how people voted before because that country employs secret vote system.\n",
        "\n",
        "They have information on how people voted in aggregate but not on voter level.\n",
        "So, now it is your work to help your evil government and earn a hero status.\n",
        "You are given data from previous elections. 8*(number of voters) features and binary result:\n",
        "\n",
        "- 1 if more then half voters voted in favor, 0 otherwise\n",
        "\n",
        "Your task is based on this information to predict how people will vote on next election."
      ]
    },
    {
      "metadata": {
        "id": "a7nQBNjiHoZe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "\n",
        "Copy auxiliary files from GitHub "
      ]
    },
    {
      "metadata": {
        "id": "zY6IVIQ9H3vP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/VVKot/mlinseconds-vote-prediction/master/mlis/utils/gridsearch.py -q\n",
        "!wget https://raw.githubusercontent.com/VVKot/mlinseconds-vote-prediction/master/mlis/utils/solutionmanager.py -q\n",
        "!wget https://raw.githubusercontent.com/VVKot/mlinseconds-vote-prediction/master/mlis/utils/speedtest.py -q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oOfJMXKsILMs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Import libraries and utils"
      ]
    },
    {
      "metadata": {
        "id": "h0u8cfq_Kb7q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip3 install tensorboardX"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tYcFLIINIOrH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "import random\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import solutionmanager as sm\n",
        "from gridsearch import GridSearch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oyZFLqciJbWN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Check whether CUDA is available"
      ]
    },
    {
      "metadata": {
        "id": "FHGP0tazJeCP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AQ6_CBWKIvO4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create neural network"
      ]
    },
    {
      "metadata": {
        "id": "T9hEryV9I4Xv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SolutionModel(nn.Module):\n",
        "    def __init__(self, input_size, output_size, solution):\n",
        "        super(SolutionModel, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "        self.solution = solution\n",
        "        self.learning_rate = solution.learning_rate\n",
        "#         self.momentum = solution.momentum\n",
        "        self.hidden_size = solution.hidden_size\n",
        "        self.activation_hidden = solution.activation_hidden\n",
        "        self.activation_output = nn.Sigmoid()\n",
        "        self.do_batch_norm = solution.do_batch_norm\n",
        "        self.layers_number = solution.layers_number\n",
        "        if self.solution.grid_search.enabled:\n",
        "            torch.manual_seed(solution.random)\n",
        "        self.hidden_size = self.solution.hidden_size\n",
        "        self.linears = nn.ModuleList([nn.Linear(self.input_size if i == 0 else self.hidden_size, self.hidden_size if i != self.solution.layers_number -1 else self.output_size) for i in range(self.solution.layers_number)]).to(device)\n",
        "        self.batch_norms = nn.ModuleList([nn.BatchNorm1d(self.hidden_size if i != self.solution.layers_number-1 else self.output_size, track_running_stats=False) for i in range(self.solution.layers_number)]).to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for i in range(len(self.linears)):\n",
        "            x = self.linears[i](x)\n",
        "            if self.solution.do_batch_norm:\n",
        "                x = self.batch_norms[i](x)\n",
        "            if i == len(self.linears)-1:\n",
        "                x = self.activation_output(x)\n",
        "            else:            \n",
        "                x = self.solution.activations[self.activation_hidden](x)\n",
        "        return x\n",
        "\n",
        "    def calc_loss(self, output, target):\n",
        "        bce_loss = nn.BCELoss()\n",
        "        loss = bce_loss(output, target)\n",
        "        return loss\n",
        "\n",
        "    def calc_predict(self, output):\n",
        "        predict = output.round()\n",
        "        return predict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "06EEkpYVI5M7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create class to store hyper parameters. Implement grid search"
      ]
    },
    {
      "metadata": {
        "id": "Jgtm0ny5JI8i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Solution():\n",
        "    def __init__(self):\n",
        "        self.best_step = 1000\n",
        "        self.activations = {\n",
        "            'relu': nn.ReLU(),\n",
        "            'hardshrink': nn.Hardshrink(1),\n",
        "            'relu6': nn.ReLU6(),\n",
        "            'leakyrelu01': nn.LeakyReLU(0.1),\n",
        "            'leakyrelu001': nn.LeakyReLU(0.01)\n",
        "        }\n",
        "        self.learning_rate = 0.001\n",
        "#         self.momentum = 0.9\n",
        "        self.hidden_size = 40\n",
        "        self.layers_number = 10\n",
        "        self.activation_hidden = 'leakyrelu01'\n",
        "        self.activation_output = 'sigmoid'\n",
        "        self.do_batch_norm = True\n",
        "        self.sols = {}\n",
        "        self.solsSum = {}\n",
        "        self.random = 0\n",
        "        self.random_grid = [_ for _ in range(10)]\n",
        "        self.layers_number_grid = [5, 10, 15, 20]\n",
        "#         self.hidden_size_grid = [20, 25, 28, 30, 32, 35, 38, 40, 45]\n",
        "        self.hidden_size_grid = [5, 10, 15, 20, 30, 40, 50]\n",
        "#         self.momentum_grid = [0.0, 0.3, 0.5, 0.8, 0.9]\n",
        "#         self.learning_rate_grid = [0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.2, 1.5]\n",
        "        self.learning_rate_grid = [0.0005, 0.001, 0.005, 0.01, 0.05, 0.1]\n",
        "        self.activation_hidden_grid = list(self.activations.keys())\n",
        "        self.grid_search = GridSearch(self)\n",
        "        self.grid_search.set_enabled(True)\n",
        "\n",
        "    def create_model(self, input_size, output_size):\n",
        "        return SolutionModel(input_size, output_size, self)\n",
        "\n",
        "    def get_key(self):\n",
        "        return \"{}_{}_{}_{}_{}_{}\".format(self.learning_rate, self.hidden_size, self.activation_hidden, self.activation_output, self.do_batch_norm, \"{0:03d}\".format(self.layers_number));\n",
        "\n",
        "    # Return number of steps used\n",
        "    def train_model(self, model, train_data, train_target, context):\n",
        "        key = self.get_key()\n",
        "        if key in self.sols and self.sols[key] == -1:\n",
        "            return\n",
        "        step = 0\n",
        "        model.to(device)\n",
        "        # Put model in train mode\n",
        "        model.train()\n",
        "#         optimizer = optim.SGD(model.parameters(), lr=self.learning_rate, momentum=self.momentum)\n",
        "        optimizer = optim.Adam(model.parameters(), lr=self.learning_rate)\n",
        "        while True:\n",
        "            time_left = context.get_timer().get_time_left()\n",
        "            # No more time left, stop training\n",
        "            if time_left < 0.1:\n",
        "                break\n",
        "            data = train_data\n",
        "            target = train_target\n",
        "            # model.parameters()...gradient set to zero\n",
        "            optimizer.zero_grad()\n",
        "            # evaluate model => model.forward(data)\n",
        "            output = model(data)\n",
        "            # if x < 0.5 predict 0 else predict 1\n",
        "            predict = model.calc_predict(output)\n",
        "            # Number of correct predictions\n",
        "            correct = predict.eq(target.view_as(predict)).long().sum().item()\n",
        "            # Total number of needed predictions\n",
        "            total = predict.view(-1).size(0)\n",
        "            if correct == total : #or (self.grid_search.enabled and step > 1000):\n",
        "                if not key in self.sols:\n",
        "                    loss = model.calc_loss(output, target)\n",
        "                    self.sols[key] = 0\n",
        "                    self.solsSum[key] = 0\n",
        "                    self.sols[key] += 1\n",
        "                    self.solsSum[key] += step\n",
        "                if correct == total:\n",
        "                    self.print_stats(step, loss, correct, total, model)\n",
        "                    print('{:.4f}'.format(float(self.solsSum[key])/self.sols[key]))\n",
        "                break\n",
        "            # calculate loss\n",
        "            loss = model.calc_loss(output, target)\n",
        "            # calculate deriviative of model.forward() and put it in model.parameters()...gradient\n",
        "            loss.backward()\n",
        "            # print progress of the learning\n",
        "            # update model: model.parameters() -= lr * gradient\n",
        "            optimizer.step()\n",
        "            step += 1\n",
        "        return step\n",
        "    \n",
        "    def print_stats(self, step, loss, correct, total, model):\n",
        "        print(\"LR={}, HS={}, Number of layers={}, ActivOut={}, Step = {} Prediction = {}/{} Error = {}\".format(\n",
        "            model.learning_rate, model.hidden_size, model.layers_number, model.activation_hidden, step, correct, total, loss.item()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RKLqM7yTJMQE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create data generator"
      ]
    },
    {
      "metadata": {
        "id": "R4LjeldMJOKK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Limits:\n",
        "    def __init__(self):\n",
        "        self.time_limit = 2.0\n",
        "        self.size_limit = 1000000\n",
        "        self.test_limit = 1.0\n",
        "\n",
        "class DataProvider:\n",
        "    def __init__(self):\n",
        "        self.number_of_cases = 10\n",
        "\n",
        "    def get_index(self, tensor_index):\n",
        "        index = 0\n",
        "        for i in range(tensor_index.size(0)):\n",
        "            index = 2*index + tensor_index[i].item()\n",
        "        return index\n",
        "\n",
        "    def calc_value(self, input_data, function_table, input_size, input_count_size):\n",
        "        count = 0\n",
        "        for i in range(input_count_size):\n",
        "            count += function_table[self.get_index(input_data[i*input_size: (i+1)*input_size])].item()\n",
        "        if count > input_count_size/2:\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    def create_data(self, data_size, input_size, input_count_size, seed):\n",
        "        torch.manual_seed(seed)\n",
        "        function_size = 1 << input_size\n",
        "        function_table = torch.ByteTensor(function_size).random_(0, 2)\n",
        "        total_input_size = input_size*input_count_size\n",
        "        data = torch.ByteTensor(data_size, total_input_size).random_(0, 2)\n",
        "        target = torch.ByteTensor(data_size)\n",
        "        for i in range(data_size):\n",
        "            target[i] = self.calc_value(data[i], function_table, input_size, input_count_size)\n",
        "        return (data.float().to(device), target.view(-1, 1).float().to(device))\n",
        "\n",
        "    def create_case_data(self, case):\n",
        "        input_size = 8\n",
        "        data_size = (1<<input_size)*32\n",
        "        input_count_size = case\n",
        "\n",
        "        data, target = self.create_data(2*data_size, input_size, input_count_size, case)\n",
        "        return sm.CaseData(case, Limits(), (data[:data_size], target[:data_size]), (data[data_size:], target[data_size:])).set_description(\"{} inputs per voter and {} voters\".format(input_size, input_count_size))\n",
        "\n",
        "class Config:\n",
        "    def __init__(self):\n",
        "        self.max_samples = 10000\n",
        "\n",
        "    def get_data_provider(self):\n",
        "        return DataProvider()\n",
        "\n",
        "    def get_solution(self):\n",
        "        return Solution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u9TKWWOXOEti",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Run training loop"
      ]
    },
    {
      "metadata": {
        "id": "9GjGcBTIOCxU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# If you want to run specific case, put number here\n",
        "sm.SolutionManager(Config()).run(case_number=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HWLKl-o2kCmV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Best hyper parameters:\n",
        "\n",
        "        self.learning_rate = 0.8\n",
        "        self.momentum = 0.9\n",
        "        self.hidden_size = 45\n",
        "        self.layers_number = 5\n",
        "        self.activation_hidden = 'relu'\n",
        "        self.activation_output = 'sigmoid'"
      ]
    }
  ]
}