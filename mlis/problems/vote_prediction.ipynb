{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "find_me.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "IuViXILkHfV5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Find Me\n",
        "\n",
        "Solve NN generalization problem using PyTorch and grid search.\n",
        "\n",
        "There are random function of 8 inputs and X random inputs added.\n",
        "We split data in two parts for training and testing"
      ]
    },
    {
      "metadata": {
        "id": "a7nQBNjiHoZe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "\n",
        "Copy auxiliary files from GitHub "
      ]
    },
    {
      "metadata": {
        "id": "zY6IVIQ9H3vP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "271e5b96-25e0-4814-c9df-aadbfb3b87d6"
      },
      "cell_type": "code",
      "source": [
        "!rm gridsearch.py solutionmanager.py speedtest.py\n",
        "!wget https://raw.githubusercontent.com/VVKot/mlinseconds-find-me/master/mlis/utils/gridsearch.py -q\n",
        "!wget https://raw.githubusercontent.com/VVKot/mlinseconds-find-me/master/mlis/utils/solutionmanager.py -q\n",
        "!wget https://raw.githubusercontent.com/VVKot/mlinseconds-find-me/master/mlis/utils/speedtest.py -q"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'gridsearch.py': No such file or directory\n",
            "rm: cannot remove 'solutionmanager.py': No such file or directory\n",
            "rm: cannot remove 'speedtest.py': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oOfJMXKsILMs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Import libraries and utils"
      ]
    },
    {
      "metadata": {
        "id": "h0u8cfq_Kb7q",
        "colab_type": "code",
        "outputId": "f11b8bda-7a47-4b52-dc00-9fc534cbe415",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "cell_type": "code",
      "source": [
        "!pip3 install tensorboard tensorboardX"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (1.12.2)\n",
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/76/89dd44458eb976347e5a6e75eb79fecf8facd46c1ce259bad54e0044ea35/tensorboardX-1.6-py2.py3-none-any.whl (129kB)\n",
            "\u001b[K    100% |████████████████████████████████| 133kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.14.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (0.14.1)\n",
            "Requirement already satisfied: grpcio>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard) (0.33.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (3.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (3.0.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.11.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorboard) (40.8.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-1.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tYcFLIINIOrH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "import random\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import solutionmanager as sm\n",
        "from gridsearch import GridSearch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oyZFLqciJbWN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Check whether CUDA is available"
      ]
    },
    {
      "metadata": {
        "id": "FHGP0tazJeCP",
        "colab_type": "code",
        "outputId": "efc7b522-1fc7-47a1-a598-e3c8eb5353cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "AQ6_CBWKIvO4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create neural network"
      ]
    },
    {
      "metadata": {
        "id": "T9hEryV9I4Xv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SolutionModel(nn.Module):\n",
        "    def __init__(self, input_size, output_size, solution):\n",
        "        super(SolutionModel, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "        self.solution = solution\n",
        "        self.learning_rate = solution.learning_rate\n",
        "        self.momentum = solution.momentum\n",
        "        self.hidden_size = solution.hidden_size\n",
        "        self.activation_hidden = solution.activation_hidden\n",
        "        self.activation_output = solution.activation_output\n",
        "        self.do_batch_norm = solution.do_batch_norm\n",
        "        self.layers_number = solution.layers_number\n",
        "        if self.solution.grid_search.enabled:\n",
        "            torch.manual_seed(solution.random)\n",
        "        self.hidden_size = self.solution.hidden_size\n",
        "        self.linears = nn.ModuleList([nn.Linear(self.input_size if i == 0 else self.hidden_size, self.hidden_size if i != self.solution.layers_number -1 else self.output_size) for i in range(self.solution.layers_number)]).to(device)\n",
        "        self.batch_norms = nn.ModuleList([nn.BatchNorm1d(self.hidden_size if i != self.solution.layers_number-1 else self.output_size, track_running_stats=False) for i in range(self.solution.layers_number)]).to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for i in range(len(self.linears)):\n",
        "            x = self.linears[i](x)\n",
        "            if self.solution.do_batch_norm:\n",
        "                x = self.batch_norms[i](x)\n",
        "            act_function = self.solution.activation_output if i == len(self.linears)-1 else self.solution.activation_hidden\n",
        "            x = self.solution.activations[act_function](x)\n",
        "        return x\n",
        "\n",
        "    def calc_loss(self, output, target):\n",
        "        bce_loss = nn.BCELoss()\n",
        "        loss = bce_loss(output, target)\n",
        "        return loss\n",
        "\n",
        "    def calc_predict(self, output):\n",
        "        predict = output.round()\n",
        "        return predict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "06EEkpYVI5M7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create class to store hyper parameters. Implement grid search"
      ]
    },
    {
      "metadata": {
        "id": "Jgtm0ny5JI8i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Solution():\n",
        "    def __init__(self):\n",
        "        self.best_step = 1000\n",
        "        self.activations = {\n",
        "            'sigmoid': nn.Sigmoid(),\n",
        "            'relu': nn.ReLU(),\n",
        "            'rrelu0103': nn.RReLU(0.1, 0.3),\n",
        "            'elu': nn.ELU(),\n",
        "            'selu': nn.SELU(),\n",
        "            'leakyrelu01': nn.LeakyReLU(0.1)\n",
        "        }\n",
        "        self.learning_rate = 0.8\n",
        "        self.momentum = 0.9\n",
        "        self.hidden_size = 45\n",
        "        self.layers_number = 5\n",
        "        self.activation_hidden = 'relu'\n",
        "        self.activation_output = 'sigmoid'\n",
        "        self.do_batch_norm = True\n",
        "        self.sols = {}\n",
        "        self.solsSum = {}\n",
        "        self.random = 0\n",
        "        self.random_grid = [_ for _ in range(10)]\n",
        "        self.layers_number_grid = [5, 6, 7, 8]\n",
        "        self.hidden_size_grid = [20, 25, 28, 30, 32, 35, 38, 40, 45]\n",
        "#         self.momentum_grid = [0.0, 0.3, 0.5, 0.8, 0.9]\n",
        "        self.learning_rate_grid = [0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.2, 1.5]\n",
        "        self.activation_hidden_grid = list(self.activations.keys())\n",
        "#         self.activation_output_grid = list(self.activations.keys())\n",
        "        self.grid_search = GridSearch(self)\n",
        "        self.grid_search.set_enabled(False)\n",
        "\n",
        "    def create_model(self, input_size, output_size):\n",
        "        return SolutionModel(input_size, output_size, self)\n",
        "\n",
        "    def get_key(self):\n",
        "        return \"{}_{}_{}_{}_{}_{}_{}\".format(self.learning_rate, self.momentum, self.hidden_size, self.activation_hidden, self.activation_output, self.do_batch_norm, \"{0:03d}\".format(self.layers_number));\n",
        "\n",
        "    # Return number of steps used\n",
        "    def train_model(self, model, train_data, train_target, context):\n",
        "        key = self.get_key()\n",
        "        if key in self.sols and self.sols[key] == -1:\n",
        "            return\n",
        "        step = 0\n",
        "        model.to(device)\n",
        "        # Put model in train mode\n",
        "        model.train()\n",
        "        optimizer = optim.SGD(model.parameters(), lr=self.learning_rate, momentum=self.momentum)\n",
        "        while True:\n",
        "            time_left = context.get_timer().get_time_left()\n",
        "            # No more time left, stop training\n",
        "            if time_left < 0.1:\n",
        "                break\n",
        "            data = train_data\n",
        "            target = train_target\n",
        "            # model.parameters()...gradient set to zero\n",
        "            optimizer.zero_grad()\n",
        "            # evaluate model => model.forward(data)\n",
        "            output = model(data)\n",
        "            # if x < 0.5 predict 0 else predict 1\n",
        "            predict = model.calc_predict(output)\n",
        "            # Number of correct predictions\n",
        "            correct = predict.eq(target.view_as(predict)).long().sum().item()\n",
        "            # Total number of needed predictions\n",
        "            total = predict.view(-1).size(0)\n",
        "#             if correct == total or (self.grid_search.enabled and step > 1000):\n",
        "#                 if not key in self.sols:\n",
        "#                     loss = model.calc_loss(output, target)\n",
        "#                     self.sols[key] = 0\n",
        "#                     self.solsSum[key] = 0\n",
        "#                     self.sols[key] += 1\n",
        "#                     self.solsSum[key] += step\n",
        "#                 if correct == total:\n",
        "#                     self.print_stats(step, loss, correct, total, model)\n",
        "#                     print('{:.4f}'.format(float(self.solsSum[key])/self.sols[key]))\n",
        "#                 break\n",
        "            # calculate loss\n",
        "            loss = model.calc_loss(output, target)\n",
        "            # calculate deriviative of model.forward() and put it in model.parameters()...gradient\n",
        "            loss.backward()\n",
        "            # print progress of the learning\n",
        "            # update model: model.parameters() -= lr * gradient\n",
        "            optimizer.step()\n",
        "            step += 1\n",
        "        return step\n",
        "    \n",
        "    def print_stats(self, step, loss, correct, total, model):\n",
        "        print(\"LR={}, Momentum={}, HS={}, Number of layers={}, ActivOut={}, Step = {} Prediction = {}/{} Error = {}\".format(model.solution.learning_rate, model.solution.momentum,\n",
        "                                                                                                              model.hidden_size, model.layers_number, model.activation_hidden, step, correct, total, loss.item()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RKLqM7yTJMQE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Evaluate the model"
      ]
    },
    {
      "metadata": {
        "id": "R4LjeldMJOKK",
        "colab_type": "code",
        "outputId": "2821333c-2b28-4aa7-fc8d-54a2d0b44e68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "cell_type": "code",
      "source": [
        "class Limits:\n",
        "    def __init__(self):\n",
        "        self.time_limit = 2.0\n",
        "        self.size_limit = 1000000\n",
        "        self.test_limit = 1.0\n",
        "\n",
        "class DataProvider:\n",
        "    def __init__(self):\n",
        "        self.number_of_cases = 10\n",
        "\n",
        "    def create_data(self, data_size, input_size, random_input_size, seed):\n",
        "        torch.manual_seed(seed)\n",
        "        function_size = 1 << input_size\n",
        "        function_input = torch.ByteTensor(function_size, input_size)\n",
        "        for i in range(function_input.size(0)):\n",
        "            fun_ind = i\n",
        "            for j in range(function_input.size(1)):\n",
        "                input_bit = fun_ind&1\n",
        "                fun_ind = fun_ind >> 1\n",
        "                function_input[i][j] = input_bit\n",
        "        function_output = torch.ByteTensor(function_size).random_(0, 2)\n",
        "\n",
        "        if data_size % function_size != 0:\n",
        "            raise \"Data gen error\"\n",
        "\n",
        "        data_input = torch.ByteTensor(data_size, input_size).view(-1, function_size, input_size).to(device)\n",
        "        target = torch.ByteTensor(data_size).view(-1, function_size).to(device)\n",
        "        for i in range(data_input.size(0)):\n",
        "            data_input[i] = function_input\n",
        "            target[i] = function_output\n",
        "        data_input = data_input.view(data_size, input_size)\n",
        "        target = target.view(data_size)\n",
        "        if random_input_size > 0:\n",
        "            data_random = torch.ByteTensor(data_size, random_input_size).random_(0, 2).to(device)\n",
        "            \n",
        "            data = torch.cat([data_input, data_random], dim=1)\n",
        "        else:\n",
        "            data = data_input\n",
        "        perm = torch.randperm(data.size(1))\n",
        "        data = data[:,perm]\n",
        "        perm = torch.randperm(data.size(0))\n",
        "        data = data[perm]\n",
        "        target = target[perm]\n",
        "        return (data.float(), target.view(-1, 1).float())\n",
        "\n",
        "    def create_case_data(self, case):\n",
        "        data_size = 256*32\n",
        "        input_size = 8\n",
        "        random_input_size = min(32, (case-1)*4)\n",
        "\n",
        "        data, target = self.create_data(2*data_size, input_size, random_input_size, case)\n",
        "        return sm.CaseData(case, Limits(), (data[:data_size], target[:data_size]), (data[data_size:], target[data_size:])).set_description(\"{} inputs and {} random inputs\".format(input_size, random_input_size))\n",
        "\n",
        "class Config:\n",
        "    def __init__(self):\n",
        "        self.max_samples = 10000\n",
        "\n",
        "    def get_data_provider(self):\n",
        "        return DataProvider()\n",
        "\n",
        "    def get_solution(self):\n",
        "        return Solution()\n",
        "\n",
        "# If you want to run specific case, put number here\n",
        "sm.SolutionManager(Config()).run(case_number=-1)\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Local CPU time mult = 0.65\n",
            "Case #1[8 inputs and 0 random inputs] Step=76 Size=7023/1000000 Time=1.9/2.0\n",
            "Train correct/total=8192/8192 Ratio/limit=1.00/1.00 Loss=0.0007047344697639346\n",
            "Test  correct/total=8192/8192 Ratio/limit=1.00/1.00 Loss=0.0007638151291757822\n",
            "\u001b[92m[OK]\u001b[0m\n",
            "Case #2[8 inputs and 4 random inputs] Step=82 Size=7203/1000000 Time=1.9/2.0\n",
            "Train correct/total=8192/8192 Ratio/limit=1.00/1.00 Loss=0.000707161845639348\n",
            "Test  correct/total=8192/8192 Ratio/limit=1.00/1.00 Loss=0.000793427461758256\n",
            "\u001b[92m[OK]\u001b[0m\n",
            "Case #3[8 inputs and 8 random inputs] Step=80 Size=7383/1000000 Time=1.9/2.0\n",
            "Train correct/total=8192/8192 Ratio/limit=1.00/1.00 Loss=0.0006573689170181751\n",
            "Test  correct/total=8192/8192 Ratio/limit=1.00/1.00 Loss=0.0006920306477695704\n",
            "\u001b[92m[OK]\u001b[0m\n",
            "Case #4[8 inputs and 12 random inputs] Step=74 Size=7563/1000000 Time=1.9/2.0\n",
            "Train correct/total=8192/8192 Ratio/limit=1.00/1.00 Loss=0.0008905095746740699\n",
            "Test  correct/total=8192/8192 Ratio/limit=1.00/1.00 Loss=0.000941755308303982\n",
            "\u001b[92m[OK]\u001b[0m\n",
            "Case #5[8 inputs and 16 random inputs] Step=74 Size=7743/1000000 Time=1.9/2.0\n",
            "Train correct/total=8192/8192 Ratio/limit=1.00/1.00 Loss=0.0011314005823805928\n",
            "Test  correct/total=8192/8192 Ratio/limit=1.00/1.00 Loss=0.0013351300731301308\n",
            "\u001b[92m[OK]\u001b[0m\n",
            "Case #6[8 inputs and 20 random inputs] Step=74 Size=7923/1000000 Time=1.9/2.0\n",
            "Train correct/total=8192/8192 Ratio/limit=1.00/1.00 Loss=0.0009636231698095798\n",
            "Test  correct/total=8192/8192 Ratio/limit=1.00/1.00 Loss=0.001142075750976801\n",
            "\u001b[92m[OK]\u001b[0m\n",
            "Case #7[8 inputs and 24 random inputs] Step=80 Size=8103/1000000 Time=1.9/2.0\n",
            "Train correct/total=8192/8192 Ratio/limit=1.00/1.00 Loss=0.0008814652101136744\n",
            "Test  correct/total=8192/8192 Ratio/limit=1.00/1.00 Loss=0.001154498546384275\n",
            "\u001b[92m[OK]\u001b[0m\n",
            "Case #8[8 inputs and 28 random inputs] Step=74 Size=8283/1000000 Time=1.9/2.0\n",
            "Train correct/total=8192/8192 Ratio/limit=1.00/1.00 Loss=0.003431461751461029\n",
            "Test  correct/total=8192/8192 Ratio/limit=1.00/1.00 Loss=0.0042311325669288635\n",
            "\u001b[92m[OK]\u001b[0m\n",
            "Case #9[8 inputs and 32 random inputs] Step=76 Size=8463/1000000 Time=1.9/2.0\n",
            "Train correct/total=8192/8192 Ratio/limit=1.00/1.00 Loss=0.0013370499946177006\n",
            "Test  correct/total=8192/8192 Ratio/limit=1.00/1.00 Loss=0.0017925417050719261\n",
            "\u001b[92m[OK]\u001b[0m\n",
            "Case #10[8 inputs and 32 random inputs] Step=74 Size=8463/1000000 Time=1.9/2.0\n",
            "Train correct/total=8192/8192 Ratio/limit=1.00/1.00 Loss=0.0021728998981416225\n",
            "Test  correct/total=8192/8192 Ratio/limit=1.00/1.00 Loss=0.0026432571467012167\n",
            "\u001b[92m[OK]\u001b[0m\n",
            "Test rate (max/mean/min/limit) = 1.000/1.000/1.000/1.000\n",
            "Average steps = 76.400\n",
            "Average time = 1.914/2.000\n",
            "Average size = 7815.000/1000000.000\n",
            "\u001b[92m[ACCEPTED]\u001b[0m you can submit now your score\n",
            "In order to submit just do a Facebook comment with your score\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HWLKl-o2kCmV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Best hyper parameters:\n",
        "\n",
        "        self.learning_rate = 0.8\n",
        "        self.momentum = 0.9\n",
        "        self.hidden_size = 45\n",
        "        self.layers_number = 5\n",
        "        self.activation_hidden = 'relu'\n",
        "        self.activation_output = 'sigmoid'"
      ]
    }
  ]
}